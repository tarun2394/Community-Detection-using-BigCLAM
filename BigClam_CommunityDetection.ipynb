{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project5_Tarun_Alapati.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH6vthyF6_QC"
      },
      "source": [
        "***Tarun Kumar Alapati***\n",
        "A20218266"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gktuPEaMVNIN"
      },
      "source": [
        "#import necessary packages\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tbHLoGI1tFe"
      },
      "source": [
        "#####Matrix Initilization and Conductance#####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmX_8w0nkBLt"
      },
      "source": [
        "#***Matrix Initilization and Conductance***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4kYdQHrLwoP"
      },
      "source": [
        "#This function take file path as the input and reads and conversts it into list of lists of all the nodes\n",
        "def get_list_words(file):\n",
        "  f = open(file, \"r\")\n",
        "  community_list = f.readlines()\n",
        "  communities =[]\n",
        "  for each_line in community_list: # iterates though each line (list)\n",
        "      communities.append([int(a) for a in each_line.split()])\n",
        "  f.close()\n",
        "  return communities\n",
        "\n",
        "#This function \n",
        "def set_factor_matrix(nodes,gt_communities, seed_communities):\n",
        "   fact_matrix = np.zeros((len(nodes),len(gt_communities)))\n",
        "   for community in range(len(seed_communities)):\n",
        "    for node in seed_communities[community]:\n",
        "      fact_matrix[node][community] = 1\n",
        "   return fact_matrix\n",
        "\n",
        "def conductance(fact_matrix,G,seed_communities):\n",
        "  for a in range(len(fact_matrix)): # Iterating through matrix\n",
        "    value_minimum = np.inf # Initialized minimum value\n",
        "    for b in range(len(fact_matrix[0])): # Iterating through each node within the factor matrix\n",
        "      conduct = nx.conductance(G, (seed_communities[b]+list(G.neighbors(a))+[a])) # Computing the conductance associated with the particular node and their associated neighbors data\n",
        "      if value_minimum > conduct: # If obtained conductance value is less then the minimum value then we reassign them\n",
        "        value_minimum = conduct # Now we swap the values obtained\n",
        "        conduct_minimum = b # This stores the node number having the minimum conductance\n",
        "      for c in list(G.neighbors(a))+[a]: # In this loop we evaluate if 'u' is locally minimal to 'c' and update it with '1' else keep at as '0'\n",
        "        fact_matrix[c][conduct_minimum] = 1\n",
        "  return fact_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PlmOLJ5tBiP"
      },
      "source": [
        "# Read the edge list data and Communities\n",
        "G = nx.read_edgelist(\"/content/drive/MyDrive/Big Data Assignments/Project5/YouTube.edgelist\", nodetype=int)\n",
        "\n",
        "gt_communities = get_list_words(\"/content/drive/MyDrive/Big Data Assignments/Project5/groundtruth_communities.txt\")\n",
        "seed_communities = get_list_words(\"/content/drive/MyDrive/Big Data Assignments/Project5/20percent_seed_communities.txt\")\n",
        "\n",
        "#Intitilaize Factor Matrix and update community list of 20 percent seeds \n",
        "fact_matrix = set_factor_matrix(G.nodes,gt_communities,seed_communities)\n",
        "#Calculate conductance for rest of the values\n",
        "fact_matrix = conductance(fact_matrix,G,seed_communities)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9dmVexmySkQ"
      },
      "source": [
        "fact_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRw4RJmNWCiJ"
      },
      "source": [
        "#Get neighbor communities\n",
        "neigh_communities = get_list_words(\"/content/drive/MyDrive/Big Data Assignments/Project5/neighborhood_seeds.txt\")\n",
        "\n",
        "#Intitilaize Factor Matrix and update community list of neighbour seeds \n",
        "\n",
        "fact_matrix_neigh = set_factor_matrix(G.nodes,gt_communities,neigh_communities)\n",
        "\n",
        "#Calculate conductance for rest of the values of neighbour seeds \n",
        "\n",
        "fact_matrix_neigh = conductance(fact_matrix,G,neigh_communities)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o64qe2z7vReS"
      },
      "source": [
        "fact_matrix_rand = np.random.rand(len(G.nodes),len(gt_communities)) # Creating a simple factor matrix with random values in range between [0,1]\n",
        "fact_matrix_rand = np.around(fact_matrix_rand,decimals=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRRuZQmeOd93"
      },
      "source": [
        "fact_matrix_rand\n",
        "#Factor Matrix Initialization for Neighborhood Seed Communities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPUSo2F3U0r"
      },
      "source": [
        "#***Matrix Factorization using BigCLAMV2.0***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkelaDkR1bRi"
      },
      "source": [
        "########This function takes number of iterations, Intial factor matrix, Communities list and Graph network and return a factorized factor matrix#####\n",
        "def bigclam_factor(n,fact_matrix,gt_communities,G):\n",
        "  percentage_change=0\n",
        "  for iter in range(n): \n",
        "    sum_nodes = fact_matrix.sum(axis=0) \n",
        "    for i in range(len(fact_matrix)): \n",
        "      neighbors_data = list(G.neighbors(i)) \n",
        "      sum_nodes_v = np.zeros(len(gt_communities))\n",
        "      Delta_1 = np.zeros(len(gt_communities))\n",
        "      for j in neighbors_data: # Iterating through each neigbor data\n",
        "        if (1-np.exp(-np.matmul(fact_matrix[i],fact_matrix[j].transpose()))): \n",
        "          Delta_12 = np.exp(-np.matmul(fact_matrix[i],fact_matrix[j].transpose()))/(1-np.exp(-np.matmul(fact_matrix[i],fact_matrix[j].transpose())))  \n",
        "        else: \n",
        "          Delta_12 = 0 \n",
        "        Delta_1 = (fact_matrix[j]*Delta_12) + Delta_1 #calculates the first term of the gradient function\n",
        "        sum_nodes_v = fact_matrix[j] + sum_nodes_v\n",
        "      Delta_2 = sum_nodes - fact_matrix[i] - sum_nodes_v \n",
        "      Delta_Main = Delta_1 - Delta_2 \n",
        "      change = 0.1*sum(Delta_Main)/sum(fact_matrix[i])\n",
        "      if change < 0.001: \n",
        "        percentage_change+=1\n",
        "      fact_matrix[i] = fact_matrix[i] + (0.001*Delta_Main) \n",
        "      nn_vector = fact_matrix[i] < 0 \n",
        "      fact_matrix[i][nn_vector] = 0 \n",
        "    if percentage_change == len(G.nodes):\n",
        "      break\n",
        "  return fact_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la9aq6EGEUx9"
      },
      "source": [
        "#method1\n",
        "\n",
        "fact_matrix_seed = bigclam_factor(300,fact_matrix, gt_communities,G)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXWHxVMmGib7"
      },
      "source": [
        "#method2\n",
        "fact_matrix_neigh_bigclam = bigclam_factor(300,fact_matrix_neigh, gt_communities,G)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQlNGggdINlI"
      },
      "source": [
        "#method3\n",
        "fact_matrix_rand_bigclam = bigclam_factor(300,fact_matrix_rand, gt_communities,G)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6d6MuJ7I9ll"
      },
      "source": [
        "fact_matrix_rand_bigclam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tbLTZOf4CuU"
      },
      "source": [
        "#***Community assignment***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XRj8HIpM4Wq"
      },
      "source": [
        "##Define delta d\n",
        "d = np.sqrt(-np.log(1-(10**-8)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_kBzlT3Yswn"
      },
      "source": [
        "#########This function takes factor matrix and d. This takes delta as the gradent and updates the community if F[u][c] >= delta \n",
        "def comm_membership(fact_matrix,d):\n",
        "  comm= dict()\n",
        "  for i in range(len(fact_matrix)):\n",
        "    for j in range(len(fact_matrix[0])): \n",
        "      if j not in comm.keys(): \n",
        "        comm[j] = []\n",
        "      if fact_matrix[i][j] >= d: # if the F[u][c] >= delta and updating the node in community\n",
        "        comm[j].append(i)\n",
        "  return comm\n",
        "\n",
        "\n",
        "###This function writes teh cmmunities and respectives nodes into a file output\n",
        "def write_dict_to_file(comm, outfile):\n",
        "  f = open(outfile, 'w')\n",
        "  for key, value in comm.items():\n",
        "      f.write(str(key)+\"::::>\"+str(value)+'\\n')\n",
        "  f.close()\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhMz66fnfs6j"
      },
      "source": [
        "#Method1 Community Assignment\n",
        "community_seed = comm_membership(fact_matrix_seed,d)\n",
        "write_dict_to_file(community_seed,'community_seed_output.txt')\n",
        "\n",
        "#Method2 Community Assignment\n",
        "\n",
        "community_neigh = comm_membership(fact_matrix_neigh_bigclam,d)\n",
        "write_dict_to_file(community_neigh,'community_neigh_output.txt')\n",
        "\n",
        "#Method3 Community Assignment\n",
        "\n",
        "community_rand = comm_membership(fact_matrix_rand_bigclam,d)\n",
        "write_dict_to_file(community_rand,'community_rand_output.txt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEk4UdrbhRRt"
      },
      "source": [
        "###Obtain Dictionary from of Cumminty and resective nodes\n",
        "gt_dict = dict()\n",
        "i=0\n",
        "for line in gt_communities: \n",
        "    gt_dict[i] = line\n",
        "    i+=1\n",
        "print(gt_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh-OZJElkLzp"
      },
      "source": [
        "##This function calculates the recall value. \n",
        "def eval_recall(gt_dict, community_seed):\n",
        "  matching = {}\n",
        "  collected = [] \n",
        "  for a in gt_dict: \n",
        "    for b in community_seed: \n",
        "      if a not in matching.keys(): \n",
        "        matching[a] = (-1,0)\n",
        "      if  matching[a][1] < len(set(community_seed[a])&set(gt_dict[b]))/len(set(gt_dict[b])): \n",
        "        if b not in collected: \n",
        "          matching[a] = (b,len(set(community_seed[a])&set(gt_dict[b]))/len(set(gt_dict[b]))) # Updated precision score for the community associated\n",
        "    collected.append(matching[a][0]) \n",
        "  recall_score = 0 \n",
        "  for a in matching: \n",
        "    recall_score = recall_score + matching[a][1] \n",
        "  recall_score = recall_score/len(gt_dict.keys()) \n",
        "  return recall_score\n",
        "\n",
        "\n",
        "##This function calculates the precision value for each of the methods \n",
        "\n",
        "def eval_precision(gt_dict, community_seed):\n",
        "  matching = {}\n",
        "  collected = [] \n",
        "  for a in gt_dict: \n",
        "    for b in community_seed: \n",
        "      if a not in matching.keys(): \n",
        "        matching[a] = (-1,0)\n",
        "      if len(set(community_seed[b])) == 0: \n",
        "        continue\n",
        "      else:\n",
        "        if b not in collected: \n",
        "          matching[a] = (b,len(set(community_seed[a])&set(gt_dict[b]))/len(set(community_seed[b]))) # Updated precision score for the community associated\n",
        "    collected.append(matching[a][0]) \n",
        "  precision_score = 0 \n",
        "  for a in matching: \n",
        "    precision_score = precision_score + matching[a][1] \n",
        "  precision_score = precision_score/len(gt_dict.keys()) \n",
        "  return precision_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMao1CzZpo51"
      },
      "source": [
        "eval_recall(gt_dict,community_seed)\n",
        "\n",
        "eval_recall(gt_dict,community_neigh)\n",
        "\n",
        "eval_recall(gt_dict,community_rand)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgDVIs6RqheS"
      },
      "source": [
        "eval_recall(gt_dict,community_seed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04O3AhIxsHLA"
      },
      "source": [
        "plt.bar([\"20 Percent Seed\",\"Neighborhood\",\"Randomly\"],[eval_recall(gt_dict,community_seed),eval_recall(gt_dict,community_neigh),eval_recall(gt_dict,community_rand)], align='center', label=\"Recall Score\")\n",
        "plt.legend()\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Recall vs. Matrix initializations')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-I_mDE8xe41"
      },
      "source": [
        "plt.bar([\"20 Percent Seed\",\"Neighborhood\",\"Random\"],[eval_precision(gt_dict,community_seed),eval_precision(gt_dict,community_neigh),eval_precision(gt_dict,community_rand)], align='center', label=\"Recall Score\")\n",
        "plt.legend()\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision vs. Matrix initializations')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twKb4Awjy_fh"
      },
      "source": [
        " **Interpretation**:Recall is generally used to assess False negatives and Precision is used to measure False Positives. Higher the value indicates less FN and FP respectively.\n",
        " \n",
        "From the above **Two** Graphs, we can say that both 20 precent seed and Neighborhood methods have same precison and recall. However, Random has zero precision and recall. Hence we can conclude that 20 Percent seed and Neighborhood are better intitilization than random\n",
        "\n"
      ]
    }
  ]
}